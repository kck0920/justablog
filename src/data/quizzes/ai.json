{
  "category": "ai",
  "quizzes": [
    {
      "id": "ai_001",
      "subcategory": "기초개념",
      "difficulty": "easy",
      "question": "AI(인공지능)의 정의로 가장 적절한 것은?",
      "options": [
        "단순히 프로그래밍된 대로만 동작하는 컴퓨터 프로그램",
        "인간의 학습능력과 추론능력, 지각능력을 인공적으로 구현한 시스템",
        "인터넷에 연결된 모든 컴퓨터 시스템",
        "자동으로 작동하는 모든 기계장치"
      ],
      "correctAnswer": 1,
      "explanation": "AI는 인간의 지능을 인공적으로 구현하여 학습, 추론, 지각 등을 수행할 수 있는 시스템을 의미합니다. 단순 프로그래밍이나 자동화와는 다른 개념입니다.",
      "tags": ["AI기초", "정의", "개념"]
    },
    {
      "id": "ai_002",
      "subcategory": "머신러닝",
      "difficulty": "medium",
      "question": "다음 중 지도학습(Supervised Learning)의 예시로 가장 적절한 것은?",
      "options": [
        "고객 데이터를 비슷한 그룹으로 자동 분류하기",
        "레이블이 있는 이미지를 학습하여 새로운 이미지 분류하기",
        "강화학습을 통해 게임 플레이 방법 학습하기",
        "데이터에서 숨겨진 패턴 찾기"
      ],
      "correctAnswer": 1,
      "explanation": "지도학습은 입력값과 그에 대한 정답(레이블)이 함께 제공되는 학습 방식입니다. 이미지 분류 작업에서 각 이미지에 대한 정답 레이블을 제공하여 학습하는 것이 대표적인 예시입니다.",
      "tags": ["머신러닝", "지도학습", "분류"]
    },
    {
      "id": "ai_003",
      "subcategory": "딥러닝",
      "difficulty": "hard",
      "question": "딥러닝에서 '과적합(Overfitting)'을 방지하기 위한 방법이 아닌 것은?",
      "options": [
        "드롭아웃(Dropout) 사용",
        "데이터 증강(Data Augmentation)",
        "학습 데이터 수 줄이기",
        "조기 종료(Early Stopping)"
      ],
      "correctAnswer": 2,
      "explanation": "과적합을 방지하기 위해서는 일반적으로 더 많은 학습 데이터를 사용하는 것이 좋습니다. 학습 데이터를 줄이는 것은 오히려 과적합을 악화시킬 수 있습니다.",
      "tags": ["딥러닝", "과적합", "모델최적화"]
    },
    {
      "id": "ai_004",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "ChatGPT가 사용하는 기술의 기반이 되는 모델 구조는?",
      "options": [
        "CNN (Convolutional Neural Network)",
        "RNN (Recurrent Neural Network)",
        "Transformer",
        "GAN (Generative Adversarial Network)"
      ],
      "correctAnswer": 2,
      "explanation": "ChatGPT는 Transformer 구조를 기반으로 하는 GPT(Generative Pre-trained Transformer) 모델을 사용합니다. Transformer는 2017년에 소개된 이후 자연어처리 분야에서 혁신적인 성능을 보여주고 있습니다.",
      "tags": ["ChatGPT", "Transformer", "자연어처리"]
    },
    {
      "id": "ai_005",
      "subcategory": "윤리",
      "difficulty": "medium",
      "question": "AI 윤리에서 '알고리즘 편향성'이란 무엇을 의미하는가?",
      "options": [
        "AI가 항상 같은 결과만을 출력하는 현상",
        "학습 데이터의 편향으로 인한 차별적 결과 도출",
        "AI의 연산 속도가 느려지는 현상",
        "AI가 인간의 감정을 이해하지 못하는 현상"
      ],
      "correctAnswer": 1,
      "explanation": "알고리즘 편향성은 AI 시스템이 학습 데이터에 내재된 편향이나 차별을 학습하여, 특정 집단에 대해 불공정한 결과를 도출하는 현상을 말합니다.",
      "tags": ["AI윤리", "편향성", "공정성"]
    },
    {
      "id": "ai_006",
      "subcategory": "컴퓨터비전",
      "difficulty": "medium",
      "question": "이미지 인식에서 'CNN(Convolutional Neural Network)'이 주로 사용되는 이유는?",
      "options": [
        "연산 속도가 매우 빠르기 때문에",
        "이미지의 공간적 특징을 효과적으로 추출할 수 있기 때문에",
        "메모리 사용량이 적기 때문에",
        "구현이 매우 간단하기 때문에"
      ],
      "correctAnswer": 1,
      "explanation": "CNN은 컨볼루션 레이어를 통해 이미지의 지역적 특징과 공간적 패턴을 효과적으로 추출할 수 있어, 이미지 인식 작업에 특히 적합합니다.",
      "tags": ["컴퓨터비전", "CNN", "이미지인식"]
    },
    {
      "id": "ai_007",
      "subcategory": "강화학습",
      "difficulty": "hard",
      "question": "강화학습에서 '탐색-활용 딜레마(Exploration-Exploitation Dilemma)'란?",
      "options": [
        "학습 속도와 정확도 사이의 균형을 맞추는 문제",
        "새로운 행동을 탐색할지, 알고 있는 최적의 행동을 선택할지 결정하는 문제",
        "보상 함수를 설계하는 과정에서 발생하는 문제",
        "학습 데이터의 양과 질을 조절하는 문제"
      ],
      "correctAnswer": 1,
      "explanation": "탐색-활용 딜레마는 에이전트가 새로운 행동을 탐색하여 더 나은 전략을 발견할지, 현재까지 알고 있는 최적의 행동을 선택할지 결정해야 하는 강화학습의 핵심 과제입니다.",
      "tags": ["강화학습", "의사결정", "전략"]
    },
    {
      "id": "ai_008",
      "subcategory": "기초개념",
      "difficulty": "easy",
      "question": "머신러닝의 세 가지 주요 학습 방식이 아닌 것은?",
      "options": [
        "지도학습(Supervised Learning)",
        "비지도학습(Unsupervised Learning)",
        "메모리학습(Memory Learning)",
        "강화학습(Reinforcement Learning)"
      ],
      "correctAnswer": 2,
      "explanation": "머신러닝의 주요 학습 방식은 지도학습, 비지도학습, 강화학습입니다. '메모리학습'은 존재하지 않는 용어입니다.",
      "tags": ["머신러닝", "학습방식", "기초"]
    },
    {
      "id": "ai_009",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "자연어처리에서 '토큰화(Tokenization)'의 목적은?",
      "options": [
        "텍스트를 암호화하기 위해",
        "텍스트를 의미 있는 단위로 분리하기 위해",
        "텍스트의 오류를 검출하기 위해",
        "텍스트의 언어를 변환하기 위해"
      ],
      "correctAnswer": 1,
      "explanation": "토큰화는 텍스트를 단어, 형태소, 또는 부분단어(subword) 등 의미 있는 단위로 분리하는 과정으로, 자연어처리의 기본적인 전처리 단계입니다.",
      "tags": ["NLP", "토큰화", "전처리"]
    },
    {
      "id": "ai_010",
      "subcategory": "윤리",
      "difficulty": "hard",
      "question": "AI 시스템의 '설명가능성(Explainability)'이 중요한 이유는?",
      "options": [
        "시스템의 실행 속도를 향상시키기 위해",
        "개발 비용을 절감하기 위해",
        "AI의 의사결정 과정을 이해하고 신뢰성을 확보하기 위해",
        "시스템의 크기를 줄이기 위해"
      ],
      "correctAnswer": 2,
      "explanation": "AI 시스템의 설명가능성은 의사결정 과정의 투명성을 확보하고, 결과에 대한 신뢰성을 보장하며, 잠재적 편향이나 오류를 식별하는 데 중요합니다.",
      "tags": ["AI윤리", "설명가능성", "신뢰성"]
    },
    {
      "id": "ai_011",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "딥러닝에서 '활성화 함수(Activation Function)'의 역할은?",
      "options": [
        "신경망의 학습 속도를 높이기 위해",
        "비선형성을 추가하여 복잡한 패턴을 학습할 수 있게 하기 위해",
        "메모리 사용량을 줄이기 위해",
        "모델의 크기를 줄이기 위해"
      ],
      "correctAnswer": 1,
      "explanation": "활성화 함수는 신경망에 비선형성을 추가하여 복잡한 패턴을 학습할 수 있게 합니다. 이를 통해 신경망이 단순한 선형 변환 이상의 기능을 수행할 수 있게 됩니다.",
      "tags": ["딥러닝", "활성화함수", "신경망"]
    },
    {
      "id": "ai_012",
      "subcategory": "자연어처리",
      "difficulty": "hard",
      "question": "BERT 모델의 가장 큰 특징은?",
      "options": [
        "단방향으로만 문맥을 파악한다",
        "양방향으로 문맥을 동시에 파악한다",
        "문장의 끝부터 시작까지 역순으로 처리한다",
        "단어를 무작위로 처리한다"
      ],
      "correctAnswer": 1,
      "explanation": "BERT(Bidirectional Encoder Representations from Transformers)는 문장의 양방향 문맥을 동시에 고려하여 단어의 의미를 파악합니다. 이는 기존의 단방향 모델들과 비교했을 때 큰 장점입니다.",
      "tags": ["NLP", "BERT", "Transformer"]
    },
    {
      "id": "ai_013",
      "subcategory": "컴퓨터비전",
      "difficulty": "medium",
      "question": "객체 탐지(Object Detection)와 이미지 분류(Image Classification)의 주요 차이점은?",
      "options": [
        "객체 탐지는 흑백 이미지만 처리할 수 있다",
        "이미지 분류는 더 많은 메모리를 사용한다",
        "객체 탐지는 물체의 위치와 종류를 모두 찾아내고, 이미지 분류는 이미지 전체의 카테고리만 판단한다",
        "이미지 분류가 더 정확하다"
      ],
      "correctAnswer": 2,
      "explanation": "객체 탐지는 이미지 내의 여러 객체의 위치(경계 상자)와 각 객체의 클래스를 찾아내는 작업이고, 이미지 분류는 이미지 전체가 어떤 카테고리에 속하는지 판단하는 작업입니다.",
      "tags": ["컴퓨터비전", "객체탐지", "이미지분류"]
    },
    {
      "id": "ai_014",
      "subcategory": "강화학습",
      "difficulty": "easy",
      "question": "강화학습에서 '보상(Reward)'의 의미는?",
      "options": [
        "에이전트의 메모리 용량",
        "에이전트의 행동에 대한 피드백 신호",
        "학습 데이터의 크기",
        "모델의 정확도"
      ],
      "correctAnswer": 1,
      "explanation": "보상은 에이전트가 수행한 행동의 좋고 나쁨을 알려주는 피드백 신호입니다. 에이전트는 이 보상을 최대화하는 방향으로 학습을 진행합니다.",
      "tags": ["강화학습", "보상", "기초개념"]
    },
    {
      "id": "ai_015",
      "subcategory": "기초개념",
      "difficulty": "easy",
      "question": "인공지능의 발전 단계 중 '약 인공지능(Weak AI)'과 '강 인공지능(Strong AI)'의 차이는?",
      "options": [
        "연산 속도의 차이",
        "메모리 사용량의 차이",
        "특정 작업만 수행 가능 vs 인간처럼 모든 지적 작업 수행 가능",
        "오프라인 동작 vs 온라인 동작"
      ],
      "correctAnswer": 2,
      "explanation": "약 인공지능은 특정 작업만을 수행할 수 있는 AI를 의미하며, 현재 대부분의 AI가 이에 해당합니다. 강 인공지능은 인간처럼 모든 지적 작업을 수행할 수 있는 수준의 AI를 의미하며, 아직 실현되지 않았습니다.",
      "tags": ["AI기초", "약인공지능", "강인공지능"]
    },
    {
      "id": "ai_016",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "자연어처리에서 '임베딩(Embedding)'의 주요 목적은?",
      "options": [
        "텍스트 데이터의 압축",
        "단어를 의미있는 벡터 공간으로 변환",
        "텍스트 암호화",
        "오타 수정"
      ],
      "correctAnswer": 1,
      "explanation": "임베딩은 단어나 문장을 고차원의 벡터 공간으로 변환하여, 의미적으로 유사한 단어들이 벡터 공간에서 가까운 위치에 있도록 합니다. 이를 통해 AI 모델이 텍스트의 의미를 더 잘 이해할 수 있게 됩니다.",
      "tags": ["NLP", "임베딩", "벡터화"]
    },
    {
      "id": "ai_017",
      "subcategory": "컴퓨터비전",
      "difficulty": "hard",
      "question": "이미지 세그멘테이션(Image Segmentation)의 종류 중 '시맨틱 세그멘테이션'과 '인스턴스 세그멘테이션'의 차이점은?",
      "options": [
        "처리 속도의 차이",
        "시맨틱은 픽셀별 클래스만 구분, 인스턴스는 같은 클래스의 개별 객체도 구분",
        "이미지 크기의 제한",
        "사용하는 신경망의 종류"
      ],
      "correctAnswer": 1,
      "explanation": "시맨틱 세그멘테이션은 각 픽셀이 어떤 클래스에 속하는지만 구분하지만, 인스턴스 세그멘테이션은 같은 클래스에 속하는 개별 객체들도 서로 구분하여 식별합니다.",
      "tags": ["컴퓨터비전", "세그멘테이션", "객체인식"]
    },
    {
      "id": "ai_018",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "배치 정규화(Batch Normalization)의 주요 장점이 아닌 것은?",
      "options": [
        "학습 속도 향상",
        "과적합 감소",
        "모델 크기 감소",
        "기울기 소실 문제 완화"
      ],
      "correctAnswer": 2,
      "explanation": "배치 정규화는 학습 속도를 향상시키고, 과적합을 줄이며, 기울기 소실 문제를 완화하는 장점이 있지만, 모델의 크기를 직접적으로 감소시키지는 않습니다.",
      "tags": ["딥러닝", "정규화", "학습최적화"]
    },
    {
      "id": "ai_019",
      "subcategory": "강화학습",
      "difficulty": "hard",
      "question": "강화학습에서 'Policy Gradient' 방법의 특징은?",
      "options": [
        "항상 최적의 해답을 보장한다",
        "행동을 직접적으로 학습하여 연속적인 행동 공간에서도 효과적이다",
        "학습 속도가 매우 빠르다",
        "메모리 사용량이 매우 적다"
      ],
      "correctAnswer": 1,
      "explanation": "Policy Gradient는 최적의 행동을 직접적으로 학습하는 방법으로, 특히 연속적인 행동 공간에서 효과적입니다. 로봇 제어와 같은 연속적인 행동이 필요한 작업에 자주 사용됩니다.",
      "tags": ["강화학습", "정책경사", "연속행동"]
    },
    {
      "id": "ai_020",
      "subcategory": "윤리",
      "difficulty": "medium",
      "question": "AI 시스템의 '프라이버시 보호'를 위한 방법이 아닌 것은?",
      "options": [
        "데이터 암호화",
        "차등 프라이버시(Differential Privacy) 적용",
        "모든 데이터를 공개적으로 저장",
        "개인식별정보 비식별화"
      ],
      "correctAnswer": 2,
      "explanation": "AI 시스템에서 프라이버시 보호를 위해서는 데이터 암호화, 차등 프라이버시 적용, 개인식별정보 비식별화 등의 방법을 사용해야 합니다. 데이터를 공개적으로 저장하는 것은 프라이버시를 심각하게 침해할 수 있습니다.",
      "tags": ["AI윤리", "프라이버시", "데이터보호"]
    },
    {
      "id": "ai_021",
      "subcategory": "기초개념",
      "difficulty": "easy",
      "question": "머신러닝에서 '과적합(Overfitting)'과 '과소적합(Underfitting)' 중 더 심각한 문제는?",
      "options": [
        "항상 과적합이 더 심각하다",
        "항상 과소적합이 더 심각하다",
        "둘 다 같은 수준으로 심각하다",
        "상황에 따라 다르며, 둘 다 해결해야 할 중요한 문제이다"
      ],
      "correctAnswer": 3,
      "explanation": "과적합과 과소적합은 모두 모델의 성능을 저하시키는 중요한 문제입니다. 어떤 것이 더 심각한지는 상황과 문제의 특성에 따라 다르며, 두 문제 모두 적절히 해결해야 합니다.",
      "tags": ["머신러닝", "모델평가", "기초개념"]
    },
    {
      "id": "ai_022",
      "subcategory": "자연어처리",
      "difficulty": "hard",
      "question": "GPT 모델의 'Attention' 메커니즘이 이전의 RNN 기반 모델들과 비교하여 가지는 가장 큰 장점은?",
      "options": [
        "항상 더 빠른 학습 속도",
        "더 적은 메모리 사용량",
        "긴 시퀀스에서의 더 나은 문맥 이해와 병렬 처리 가능",
        "더 작은 모델 크기"
      ],
      "correctAnswer": 2,
      "explanation": "Attention 메커니즘은 입력 시퀀스의 모든 부분을 동시에 고려할 수 있어 긴 문장에서도 문맥을 잘 파악할 수 있으며, 병렬 처리가 가능해 처리 속도도 빠릅니다. RNN은 순차적 처리로 인해 긴 시퀀스에서 정보 손실이 발생할 수 있습니다.",
      "tags": ["NLP", "Attention", "Transformer"]
    },
    {
      "id": "ai_023",
      "subcategory": "컴퓨터비전",
      "difficulty": "medium",
      "question": "딥러닝 기반 이미지 인식에서 '데이터 증강(Data Augmentation)'을 사용하는 주된 이유는?",
      "options": [
        "모델의 실행 속도를 높이기 위해",
        "학습 데이터의 다양성을 증가시켜 과적합을 방지하기 위해",
        "이미지의 화질을 개선하기 위해",
        "저장 공간을 절약하기 위해"
      ],
      "correctAnswer": 1,
      "explanation": "데이터 증강은 기존 이미지를 회전, 반전, 크기 조정 등으로 변형하여 학습 데이터의 다양성을 높입니다. 이를 통해 모델이 더 일반화된 특징을 학습하게 되어 과적합을 방지할 수 있습니다.",
      "tags": ["컴퓨터비전", "데이터증강", "과적합방지"]
    },
    {
      "id": "ai_024",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "딥러닝에서 '드롭아웃(Dropout)'을 학습 시에만 사용하고 추론 시에는 사용하지 않는 이유는?",
      "options": [
        "추론 속도를 높이기 위해",
        "메모리 사용량을 줄이기 위해",
        "모든 뉴런의 정보를 활용하여 최적의 예측을 하기 위해",
        "모델 크기를 줄이기 위해"
      ],
      "correctAnswer": 2,
      "explanation": "드롭아웃은 학습 중 과적합을 방지하기 위한 기법입니다. 추론 시에는 가능한 모든 정보를 활용하여 최적의 예측을 해야 하므로, 모든 뉴런을 사용합니다. 대신 각 뉴런의 출력값을 드롭아웃 비율만큼 스케일링합니다.",
      "tags": ["딥러닝", "드롭아웃", "정규화"]
    },
    {
      "id": "ai_025",
      "subcategory": "윤리",
      "difficulty": "hard",
      "question": "AI 시스템의 '설명가능성(Explainability)'과 '성능(Performance)' 사이의 관계는?",
      "options": [
        "항상 비례한다",
        "항상 반비례한다",
        "일반적으로 트레이드오프(trade-off) 관계가 있다",
        "서로 무관하다"
      ],
      "correctAnswer": 2,
      "explanation": "AI 시스템에서 설명가능성과 성능은 일반적으로 트레이드오프 관계에 있습니다. 더 복잡하고 성능이 좋은 모델일수록 의사결정 과정을 설명하기 어려워지는 경향이 있습니다. 이는 특히 딥러닝 모델에서 두드러지게 나타납니다.",
      "tags": ["AI윤리", "설명가능성", "성능"]
    },
    {
      "id": "ai_026",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "자연어처리에서 'BLEU 점수'가 측정하는 것은?",
      "options": [
        "텍스트의 감정 분석 정확도",
        "기계 번역의 품질",
        "문장의 문법적 정확성",
        "텍스트 생성 속도"
      ],
      "correctAnswer": 1,
      "explanation": "BLEU(Bilingual Evaluation Understudy) 점수는 기계 번역의 품질을 평가하는 지표입니다. 번역된 텍스트와 참조 번역을 비교하여 n-gram 기반의 정확도를 계산합니다.",
      "tags": ["NLP", "평가지표", "기계번역"]
    },
    {
      "id": "ai_027",
      "subcategory": "강화학습",
      "difficulty": "hard",
      "question": "강화학습에서 'Actor-Critic' 방법의 특징은?",
      "options": [
        "단순히 행동만 학습한다",
        "단순히 가치함수만 학습한다",
        "행동 정책(Actor)과 가치함수(Critic)를 동시에 학습한다",
        "환경 모델을 직접 학습한다"
      ],
      "correctAnswer": 2,
      "explanation": "Actor-Critic 방법은 행동을 선택하는 Actor와 상태/행동의 가치를 평가하는 Critic을 동시에 학습합니다. Critic의 평가를 바탕으로 Actor가 더 나은 행동을 학습할 수 있게 됩니다.",
      "tags": ["강화학습", "Actor-Critic", "정책학습"]
    },
    {
      "id": "ai_028",
      "subcategory": "컴퓨터비전",
      "difficulty": "medium",
      "question": "컴퓨터비전에서 '전이학습(Transfer Learning)'을 사용하는 주된 이유는?",
      "options": [
        "모델의 크기를 줄이기 위해",
        "학습 속도를 높이고 적은 데이터로도 좋은 성능을 내기 위해",
        "이미지의 화질을 개선하기 위해",
        "메모리 사용량을 줄이기 위해"
      ],
      "correctAnswer": 1,
      "explanation": "전이학습은 대규모 데이터셋에서 사전 학습된 모델을 활용하여, 적은 양의 데이터로도 새로운 작업에서 좋은 성능을 낼 수 있게 합니다. 또한 학습 시간도 크게 단축할 수 있습니다.",
      "tags": ["컴퓨터비전", "전이학습", "모델최적화"]
    },
    {
      "id": "ai_029",
      "subcategory": "기초개념",
      "difficulty": "easy",
      "question": "머신러닝에서 '특성(Feature)'과 '레이블(Label)'의 관계는?",
      "options": [
        "특성은 출력값, 레이블은 입력값이다",
        "특성은 입력값, 레이블은 예측하고자 하는 출력값이다",
        "둘 다 입력값이다",
        "둘 다 출력값이다"
      ],
      "correctAnswer": 1,
      "explanation": "특성은 모델의 입력으로 사용되는 데이터의 속성이며, 레이블은 모델이 예측해야 하는 목표값입니다. 지도학습에서는 특성을 기반으로 레이블을 예측하도록 학습합니다.",
      "tags": ["머신러닝", "기초개념", "데이터구조"]
    },
    {
      "id": "ai_030",
      "subcategory": "윤리",
      "difficulty": "medium",
      "question": "AI 시스템의 '공정성(Fairness)'을 평가하는 방법으로 적절하지 않은 것은?",
      "options": [
        "인구통계학적 균형성 검사",
        "예측 결과의 균등성 검사",
        "처리 속도 측정",
        "기회의 균등성 검사"
      ],
      "correctAnswer": 2,
      "explanation": "AI 시스템의 공정성은 주로 인구통계학적 균형성, 예측 결과의 균등성, 기회의 균등성 등을 통해 평가됩니다. 처리 속도는 시스템의 성능 지표이며 공정성과는 직접적인 관련이 없습니다.",
      "tags": ["AI윤리", "공정성", "평가지표"]
    },
    {
      "id": "ai_031",
      "subcategory": "딥러닝",
      "difficulty": "hard",
      "question": "딥러닝에서 '적대적 공격(Adversarial Attack)'이란?",
      "options": [
        "모델의 학습을 방해하는 노이즈 추가",
        "의도적으로 모델을 오분류하게 만드는 미세한 입력 변형",
        "모델의 가중치를 직접 수정",
        "학습 데이터의 무작위 변형"
      ],
      "correctAnswer": 1,
      "explanation": "적대적 공격은 사람의 눈으로는 거의 구별할 수 없는 미세한 변형을 입력에 추가하여, 모델이 잘못된 예측을 하도록 만드는 기법입니다. 이는 AI 시스템의 보안 취약점을 드러내는 중요한 연구 분야입니다.",
      "tags": ["딥러닝", "보안", "적대적예제"]
    },
    {
      "id": "ai_032",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "자연어처리에서 'Few-shot Learning'이란?",
      "options": [
        "학습 데이터가 전혀 없는 상태에서 학습하는 방법",
        "사전 학습된 모델이 명시적인 예제 없이도 새로운 작업을 수행하는 능력",
        "모든 데이터를 한 번에 학습하는 방법",
        "학습을 전혀 하지 않는 방법"
      ],
      "correctAnswer": 1,
      "explanation": "Few-shot Learning은 새로운 작업이나 개념을 학습할 때 소수의 예제만으로도 효과적으로 학습할 수 있는 능력을 의미합니다. GPT와 같은 대규모 언어 모델들이 이러한 능력을 보여주고 있습니다.",
      "tags": ["NLP", "Few-shot", "전이학습"]
    },
    {
      "id": "ai_033",
      "subcategory": "컴퓨터비전",
      "difficulty": "hard",
      "question": "컴퓨터비전에서 'NeRF(Neural Radiance Fields)'의 주요 목적은?",
      "options": [
        "이미지 분류의 정확도 향상",
        "3D 장면을 새로운 시점에서 렌더링",
        "이미지 압축 효율 개선",
        "실시간 객체 추적"
      ],
      "correctAnswer": 1,
      "explanation": "NeRF는 여러 각도에서 촬영된 2D 이미지들로부터 3D 장면을 학습하고, 새로운 시점에서의 뷰를 생성할 수 있는 신경망 기반 기술입니다. 이는 3D 장면 표현과 렌더링에 혁신을 가져왔습니다.",
      "tags": ["컴퓨터비전", "3D렌더링", "신경망렌더링"]
    },
    {
      "id": "ai_034",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "딥러닝에서 'Gradient Clipping'을 사용하는 주된 이유는?",
      "options": [
        "메모리 사용량 감소",
        "학습 속도 향상",
        "기울기 폭발 문제 방지",
        "모델 크기 축소"
      ],
      "correctAnswer": 2,
      "explanation": "Gradient Clipping은 기울기의 크기가 특정 임계값을 넘어가지 않도록 제한하는 기법입니다. 이를 통해 기울기 폭발 문제를 방지하고 학습을 안정화할 수 있습니다.",
      "tags": ["딥러닝", "최적화", "학습안정화"]
    },
    {
      "id": "ai_035",
      "subcategory": "강화학습",
      "difficulty": "hard",
      "question": "강화학습에서 'Intrinsic Motivation'의 역할은?",
      "options": [
        "외부 보상만으로 학습",
        "내재적 호기심이나 탐험을 통한 학습 동기 부여",
        "학습 속도 향상",
        "메모리 사용량 최적화"
      ],
      "correctAnswer": 1,
      "explanation": "Intrinsic Motivation은 에이전트가 외부 보상 없이도 환경을 탐험하고 학습하도록 동기를 부여하는 메커니즘입니다. 이는 호기심이나 새로움 추구와 같은 내재적 동기를 모델링합니다.",
      "tags": ["강화학습", "내재적동기", "탐험"]
    },
    {
      "id": "ai_036",
      "subcategory": "윤리",
      "difficulty": "medium",
      "question": "AI 시스템의 '견고성(Robustness)'을 평가하는 방법으로 가장 적절한 것은?",
      "options": [
        "일반적인 테스트 데이터에서의 성능만 측정",
        "다양한 노이즈와 예외적 상황에서의 성능 테스트",
        "실행 속도 측정",
        "메모리 사용량 측정"
      ],
      "correctAnswer": 1,
      "explanation": "AI 시스템의 견고성은 노이즈가 있는 입력, 예상치 못한 상황, 적대적 공격 등 다양한 조건에서도 안정적으로 작동하는 능력을 의미합니다. 이는 실제 환경에서의 신뢰성을 보장하는 중요한 특성입니다.",
      "tags": ["AI윤리", "견고성", "신뢰성"]
    },
    {
      "id": "ai_037",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "자연어처리에서 'Prompt Engineering'의 중요성이 부각되는 이유는?",
      "options": [
        "모델의 실행 속도를 높이기 위해",
        "같은 모델이라도 프롬프트에 따라 매우 다른 결과를 생성할 수 있기 때문에",
        "모델의 크기를 줄이기 위해",
        "학습 데이터를 줄이기 위해"
      ],
      "correctAnswer": 1,
      "explanation": "Prompt Engineering은 AI 모델에게 어떻게 질문하고 지시할지를 설계하는 기술입니다. 특히 GPT와 같은 대규모 언어 모델은 프롬프트의 구성에 따라 매우 다른 품질의 결과를 생성할 수 있어, 효과적인 프롬프트 설계가 중요합니다.",
      "tags": ["NLP", "프롬프트엔지니어링", "LLM"]
    },
    {
      "id": "ai_038",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "딥러닝에서 'Knowledge Distillation'의 목적은?",
      "options": [
        "모델의 학습 속도 향상",
        "큰 모델의 지식을 작은 모델로 전달하여 효율적인 모델 생성",
        "데이터 증강",
        "모델의 정확도 향상"
      ],
      "correctAnswer": 1,
      "explanation": "Knowledge Distillation은 큰 모델(교사 모델)의 지식을 작은 모델(학생 모델)로 전달하는 기술입니다. 이를 통해 원래 모델보다 크기가 작으면서도 비슷한 성능을 내는 모델을 만들 수 있습니다.",
      "tags": ["딥러닝", "모델압축", "지식증류"]
    },
    {
      "id": "ai_039",
      "subcategory": "컴퓨터비전",
      "difficulty": "hard",
      "question": "컴퓨터비전에서 'Self-Attention'이 기여한 주요 발전은?",
      "options": [
        "이미지 압축률 향상",
        "학습 속도 개선",
        "이미지의 전역적 문맥 정보를 효과적으로 처리",
        "메모리 사용량 감소"
      ],
      "correctAnswer": 2,
      "explanation": "Self-Attention 메커니즘은 이미지의 모든 부분 간의 관계를 동시에 고려할 수 있어, 전역적 문맥 정보를 효과적으로 처리할 수 있습니다. 이는 특히 객체 간의 관계나 장면 이해에 큰 도움이 됩니다.",
      "tags": ["컴퓨터비전", "Self-Attention", "Transformer"]
    },
    {
      "id": "ai_040",
      "subcategory": "강화학습",
      "difficulty": "medium",
      "question": "강화학습에서 'Curriculum Learning'의 개념은?",
      "options": [
        "한 번에 모든 어려운 작업을 학습",
        "쉬운 작업부터 점차 어려운 작업으로 진행하며 학습",
        "무작위 순서로 작업을 학습",
        "가장 어려운 작업만 반복 학습"
      ],
      "correctAnswer": 1,
      "explanation": "Curriculum Learning은 인간의 학습 방식을 모방한 접근법으로, 쉬운 작업부터 시작하여 점진적으로 더 어려운 작업을 학습하도록 합니다. 이를 통해 더 효율적이고 효과적인 학습이 가능합니다.",
      "tags": ["강화학습", "커리큘럼학습", "학습전략"]
    },
    {
      "id": "ai_041",
      "subcategory": "자연어처리",
      "difficulty": "medium",
      "question": "자연어처리에서 'Zero-shot Learning'이란?",
      "options": [
        "학습 데이터가 전혀 없는 상태에서 학습하는 방법",
        "사전 학습된 모델이 명시적인 예제 없이도 새로운 작업을 수행하는 능력",
        "모든 데이터를 한 번에 학습하는 방법",
        "학습을 전혀 하지 않는 방법"
      ],
      "correctAnswer": 1,
      "explanation": "Zero-shot Learning은 특정 작업에 대한 학습 예제 없이도, 작업에 대한 자연어 설명만으로 새로운 작업을 수행할 수 있는 능력을 의미합니다. 이는 대규모 언어 모델의 중요한 특징 중 하나입니다.",
      "tags": ["NLP", "Zero-shot", "전이학습"]
    },
    {
      "id": "ai_042",
      "subcategory": "컴퓨터비전",
      "difficulty": "hard",
      "question": "컴퓨터비전에서 'NeRF(Neural Radiance Fields)'의 주요 목적은?",
      "options": [
        "이미지 분류의 정확도 향상",
        "3D 장면을 새로운 시점에서 렌더링",
        "이미지 압축 효율 개선",
        "실시간 객체 추적"
      ],
      "correctAnswer": 1,
      "explanation": "NeRF는 여러 각도에서 촬영된 2D 이미지들로부터 3D 장면을 학습하고, 새로운 시점에서의 뷰를 생성할 수 있는 신경망 기반 기술입니다. 이는 3D 장면 표현과 렌더링에 혁신을 가져왔습니다.",
      "tags": ["컴퓨터비전", "3D렌더링", "신경망렌더링"]
    },
    {
      "id": "ai_043",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "딥러닝에서 'Gradient Clipping'을 사용하는 주된 이유는?",
      "options": [
        "메모리 사용량 감소",
        "학습 속도 향상",
        "기울기 폭발 문제 방지",
        "모델 크기 축소"
      ],
      "correctAnswer": 2,
      "explanation": "Gradient Clipping은 기울기의 크기가 특정 임계값을 넘어가지 않도록 제한하는 기법입니다. 이를 통해 기울기 폭발 문제를 방지하고 학습을 안정화할 수 있습니다.",
      "tags": ["딥러닝", "최적화", "학습안정화"]
    },
    {
      "id": "ai_044",
      "subcategory": "강화학습",
      "difficulty": "hard",
      "question": "강화학습에서 'Intrinsic Motivation'의 역할은?",
      "options": [
        "외부 보상만으로 학습",
        "내재적 호기심이나 탐험을 통한 학습 동기 부여",
        "학습 속도 향상",
        "메모리 사용량 최적화"
      ],
      "correctAnswer": 1,
      "explanation": "Intrinsic Motivation은 에이전트가 외부 보상 없이도 환경을 탐험하고 학습하도록 동기를 부여하는 메커니즘입니다. 이는 호기심이나 새로움 추구와 같은 내재적 동기를 모델링합니다.",
      "tags": ["강화학습", "내재적동기", "탐험"]
    },
    {
      "id": "ai_045",
      "subcategory": "윤리",
      "difficulty": "medium",
      "question": "AI 시스템의 '견고성(Robustness)'을 평가하는 방법으로 가장 적절한 것은?",
      "options": [
        "일반적인 테스트 데이터에서의 성능만 측정",
        "다양한 노이즈와 예외적 상황에서의 성능 테스트",
        "실행 속도 측정",
        "메모리 사용량 측정"
      ],
      "correctAnswer": 1,
      "explanation": "AI 시스템의 견고성은 노이즈가 있는 입력, 예상치 못한 상황, 적대적 공격 등 다양한 조건에서도 안정적으로 작동하는 능력을 의미합니다. 이는 실제 환경에서의 신뢰성을 보장하는 중요한 특성입니다.",
      "tags": ["AI윤리", "견고성", "신뢰성"]
    },
    {
      "id": "ai_046",
      "subcategory": "자연어처리",
      "difficulty": "hard",
      "question": "대규모 언어 모델에서 '환각(Hallucination)' 현상이란?",
      "options": [
        "모델이 전혀 작동하지 않는 현상",
        "모델이 사실이 아닌 정보를 실제인 것처럼 생성하는 현상",
        "모델의 메모리가 부족한 현상",
        "모델의 처리 속도가 느려지는 현상"
      ],
      "correctAnswer": 1,
      "explanation": "환각은 대규모 언어 모델이 학습 데이터에 없는 거짓 정보를 마치 사실인 것처럼 자신감 있게 생성하는 현상입니다. 이는 현재 AI 모델의 중요한 한계점 중 하나로 인식되고 있습니다.",
      "tags": ["NLP", "LLM", "한계점"]
    },
    {
      "id": "ai_047",
      "subcategory": "딥러닝",
      "difficulty": "medium",
      "question": "딥러닝에서 'Mixup' 기법의 주요 목적은?",
      "options": [
        "학습 속도 향상",
        "모델의 일반화 성능 향상",
        "메모리 사용량 감소",
        "모델 크기 축소"
      ],
      "correctAnswer": 1,
      "explanation": "Mixup은 서로 다른 학습 데이터를 무작위로 섞어 새로운 학습 데이터를 생성하는 기법입니다. 이를 통해 모델이 더 부드러운 결정 경계를 학습하게 되어 일반화 성능이 향상됩니다.",
      "tags": ["딥러닝", "데이터증강", "일반화"]
    },
    {
      "id": "ai_048",
      "subcategory": "컴퓨터비전",
      "difficulty": "hard",
      "question": "컴퓨터비전에서 'Vision Transformer(ViT)'가 가져온 주요 혁신은?",
      "options": [
        "더 적은 컴퓨팅 파워 사용",
        "CNN의 지역적 특징 추출 한계를 극복하고 전역적 관계 파악 가능",
        "더 작은 모델 크기",
        "더 빠른 학습 속도"
      ],
      "correctAnswer": 1,
      "explanation": "Vision Transformer는 자연어처리에서 성공적이었던 Transformer 구조를 이미지 처리에 적용한 모델입니다. 이는 CNN의 지역적 특징 추출 한계를 넘어 이미지의 전역적 관계를 효과적으로 파악할 수 있게 했습니다.",
      "tags": ["컴퓨터비전", "Transformer", "구조혁신"]
    },
    {
      "id": "ai_049",
      "subcategory": "강화학습",
      "difficulty": "medium",
      "question": "강화학습에서 'Imitation Learning'의 주요 특징은?",
      "options": [
        "무작위 탐색을 통한 학습",
        "전문가의 행동을 모방하여 학습",
        "보상 없이 학습",
        "환경 모델을 직접 학습"
      ],
      "correctAnswer": 1,
      "explanation": "Imitation Learning은 전문가의 시연이나 행동 데이터를 관찰하고 모방함으로써 학습하는 방법입니다. 이는 복잡한 작업에서 보상 설계의 어려움을 우회할 수 있는 효과적인 접근법입니다.",
      "tags": ["강화학습", "모방학습", "전문가데이터"]
    },
    {
      "id": "ai_050",
      "subcategory": "윤리",
      "difficulty": "medium",
      "question": "AI 시스템의 '투명성(Transparency)'을 높이기 위한 가장 효과적인 방법은?",
      "options": [
        "모든 코드를 공개하는 것",
        "의사결정 과정과 근거를 명확히 설명할 수 있게 설계",
        "처리 속도를 높이는 것",
        "더 많은 데이터를 사용하는 것"
      ],
      "correctAnswer": 1,
      "explanation": "AI 시스템의 투명성은 단순히 코드를 공개하는 것이 아니라, 시스템이 왜 특정 결정을 내렸는지 그 과정과 근거를 이해관계자들이 이해할 수 있도록 설명할 수 있어야 합니다. 이는 AI 시스템에 대한 신뢰를 구축하는 핵심 요소입니다.",
      "tags": ["AI윤리", "투명성", "설명가능성"]
    }
  ]
} 